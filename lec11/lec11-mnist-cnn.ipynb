{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import random\n",
    "\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "\n",
    "tf.set_random_seed(777)\n",
    "\n",
    "mnist = input_data.read_data_sets(\"MNIST_data/\", one_hot=True)\n",
    "\n",
    "#파라미터 값\n",
    "learning_rate = 0.001\n",
    "training_epochs = 5\n",
    "batch_size =100\n",
    "\n",
    "#input placeholder\n",
    "X = tf.placeholder(tf.float32, [None, 784]) #784개의 값을 가져오고 N개의 이미지\n",
    "X_img = tf.reshape(X,[-1,28,28,1]) \n",
    "Y = tf.placeholder(tf.float32, [None, 10])\n",
    "\n",
    "#Conv layer1  Imgin shape=(?,28,28,1)\n",
    "W1 = tf.Variable(tf.random_normal([3,3,1,32], stddev=0.01)) #32개의 filer사용\n",
    "\n",
    "   # Conv layer  --> (?,28,28,32) 32개의 필터를 사용해서 32개의 Conv값이 생긴다.\n",
    "L1 = tf.nn.conv2d(X_img, W1, strides=[1,1,1,1],padding='SAME')\n",
    "L1 = tf.nn.relu(L1)\n",
    "L1 = tf.nn.max_pool(L1, ksize=[1,2,2,1],\n",
    "                   strides=[1,2,2,1], padding='SAME') #relu를 통과시키고 max_pooling을 한다.\n",
    "   # kernal size는 2*2 stride는 2*2 \n",
    "   # Pooling Max를 거치면 stride가 2이므로  14*14 --> (?,14,14,32) 32개의 channel\n",
    "\n",
    "\n",
    "#Conv layer 2 Imgin shape=(?,14,14,32) 위의 Conv layer1 거친 후이므로.\n",
    "W2 = tf.Variable(tf.random_normal([3,3,32,64], stddev=0.01)) #32는 앞에서 받은 값.이번엔 64개의 필터\n",
    "    #Conv layer  --> (?,14,14,64)\n",
    "L2 = tf.nn.conv2d(L1, W2, strides=[1,1,1,1], padding='SAME')\n",
    "L2 = tf.nn.relu(L2) # relu를 통화. 사이즈 변경 안하고 pooling한다.\n",
    "L2 = tf.nn.max_pool(L2, ksize=[1,2,2,1], strides=[1,2,2,1], padding='SAME')\n",
    "    #pooling 거치면서 stride가 2이므로 7*7이되다.--> (?,7,7,64)\n",
    "L2_flat = tf.reshape(L2, [-1,7*7*64]) # -1은 n개의 값이고, 쫙 펼치기 위해 reshape함. 7*7*64가 n개.\n",
    "\n",
    "# 마지막 단계 Fully Connected layer\n",
    "    #final FC 7*7*64 inputs ==> 10 outputs 0~9까지 예측하기위해.\n",
    "W3 = tf.get_variable(\"W3\", shape=[7*7*64,10],\n",
    "                        initializer=tf.contrib.layers.xavier_initializer())\n",
    "b = tf.Variable(tf.random_normal([10]))\n",
    "hypothesis = tf.matmul(L2_flat, W3) + b # xw + b : x는 L2\n",
    "\n",
    "#define cost/loss & optimizer 이전과 같이 하면 된다\n",
    "cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=hypothesis, labels = Y))\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate = learning_rate).minimize(cost)\n",
    "\n",
    "#initialize\n",
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "# train my model\n",
    "print('Learning started. It takes sometime.')\n",
    "for epoch in range(training_epochs):\n",
    "    avg_cost = 0\n",
    "    total_batch = int(mnist.train.num_examples / batch_size)\n",
    "\n",
    "    for i in range(total_batch):\n",
    "        batch_xs, batch_ys = mnist.train.next_batch(batch_size)\n",
    "        feed_dict = {X: batch_xs, Y: batch_ys}\n",
    "        c, _ = sess.run([cost, optimizer], feed_dict=feed_dict)\n",
    "        avg_cost += c / total_batch\n",
    "\n",
    "    print('Epoch:', '%04d' % (epoch + 1), 'cost =', '{:.9f}'.format(avg_cost))\n",
    "\n",
    "print('Learning Finished!')\n",
    "\n",
    "# Test model and check accuracy\n",
    "correct_prediction = tf.equal(tf.argmax(logits, 1), tf.argmax(Y, 1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "print('Accuracy:', sess.run(accuracy, feed_dict={\n",
    "      X: mnist.test.images, Y: mnist.test.labels}))\n",
    "\n",
    "# Get one and predict\n",
    "r = random.randint(0, mnist.test.num_examples - 1)\n",
    "print(\"Label: \", sess.run(tf.argmax(mnist.test.labels[r:r + 1], 1)))\n",
    "print(\"Prediction: \", sess.run(\n",
    "    tf.argmax(hypothesis, 1), feed_dict={X: mnist.test.images[r:r + 1]}))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
